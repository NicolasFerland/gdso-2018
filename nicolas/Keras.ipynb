{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips from http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review\n",
    "- Use encoder-decoder, upsampling by doing a reverse convolution and concatenating with the feature maps that were before the downsampling or by copying the index of the max-pooling\n",
    "- Use VGG convolution layers trained on imagenet and remove the final FC layers or use ResNet for the encoder.\n",
    "- Use dillated convolution rather than downsampling (they still do some pooling for downsampling, but most of the increase in field of view is from the dillatation)\n",
    "- It is common to have a predicted segmentation map that is 1/8th of the input image size. One uses interpolation to get the final segmentation map.\n",
    "- Use a fully connected CRF after interpolation (trained separately)\n",
    "- Use residual conv unit, multi-resolution fusion and chained residual pooling to combine multi-resolution input\n",
    "- Very large kernel are useful for the classification part of the network. They play a role similar as the FC layer at the end of a classifier. They are better to use a large receptive field that deep network like ResNet even though ResNet has theoretically a very large receptive field. kxk convolution are approximated by 1xk+kx1 convolutions to reduce the number of parameter and the computational expense.\n",
    "\n",
    "What I think about this particular case (road detection):\n",
    "- It is not needed to have large field of view, but it is important to have a good resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from keras import layers, regularizers\n",
    "#from keras import models\n",
    "from keras.models import Model, Sequential\n",
    "from keras import callbacks\n",
    "from time import time\n",
    "from keras import backend as K\n",
    "#import tensorflow as tf\n",
    "K.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 8, 325, 325) (99, 1, 1300, 1300) (99, 325, 325)\n"
     ]
    }
   ],
   "source": [
    "modelList = []\n",
    "history = []\n",
    "xaxis = []\n",
    "class TimeHistory(callbacks.Callback):\n",
    "    def __init__(self, seconds=np.inf):\n",
    "        super(callbacks.Callback, self).__init__()\n",
    "        self.seconds = seconds\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "        self.start = time()\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time() - self.start)\n",
    "        if time() - self.start > self.seconds: # if not defined, there is no limit since it is np.inf\n",
    "            self.model.stop_training = True\n",
    "            print('Stopping after %s seconds.' % self.seconds)\n",
    "                \n",
    "def Plot(i, text = 'acc', label = ''):\n",
    "    plt.plot(xaxis[i], history[i].history['val_'+text], label = label)\n",
    "    \n",
    "def retrain(i_model, batchsize=99, nepochs=10, timelimit=np.inf):\n",
    "    time_callback = TimeHistory(timelimit)\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0., patience=10)\n",
    "    history[i_model].history = list(history[i_model].history)\n",
    "    history[i_model].history.append(modelList[i_model].fit_generator(generator(batchsize), \n",
    "                    steps_per_epoch(989-yVal.shape[0])//batchsize,\n",
    "                   epochs=nepochs, verbose=2, validation_data=([xMulVal,xPanVal],yVal),callbacks=[time_callback, es]))\n",
    "    xaxis[i_model].append(time_callback.times)\n",
    "    \n",
    "def generator(batchsize):\n",
    "    while True:\n",
    "        for i in range(10):\n",
    "            print('  file', i)\n",
    "            xMul = np.load(r'..\\data\\xMul'+str(i)+'.npy')\n",
    "            xPan = np.load(r'..\\data\\xPan'+str(i)+'.npy')\n",
    "            y = np.load(r'..\\data\\y325_'+str(i)+'.npy') # I will use the 325x325 resolution for the target\n",
    "            xMul = (xMul - 414.1505843473475)/271.51272549425477\n",
    "            xPan = (xPan - 532.8910415421709)/318.8023222567299\n",
    "            j=0\n",
    "            while j<xMul.shape[0]:\n",
    "                print('    ',j, '/', xMul.shape[0])\n",
    "                yield ([xMul[j:j+batchsize], xPan[j:j+batchsize]], y[j:j+batchsize])\n",
    "                j+= batchsize\n",
    "                \n",
    "# load Validation data\n",
    "xMulVal = np.load(r'..\\data\\xMulVal.npy')\n",
    "xPanVal = np.load(r'..\\data\\xPanVal.npy')\n",
    "yVal = np.load(r'..\\data\\yVal325.npy')\n",
    "xMulVal = (xMulVal - 414.1505843473475)/271.51272549425477\n",
    "xPanVal = (xPanVal - 532.8910415421709)/318.8023222567299\n",
    "\n",
    "print(xMulVal.shape,xPanVal.shape, yVal.shape)\n",
    "\n",
    "def train(batchsize=99, nepochs=10, timelimit=np.inf):\n",
    "    XMul = layers.Input(shape=xMulVal.shape[1:])\n",
    "    XPan = layers.Input(shape=xPanVal.shape[1:])\n",
    "    \n",
    "    # Actual neural netowrk given by function NN\n",
    "    Y = NN(XMul,XPan)\n",
    "    \n",
    "    model = Model(inputs=[XMul,XPan], outputs=Y)\n",
    "\n",
    "    time_callback = TimeHistory(timelimit)\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', min_delta=0., patience=10)\n",
    "    model.compile(optimizer='adam', metrics=['acc'],\n",
    "                  loss='binary_crossentropy')\n",
    "    history.append(model.fit_generator(generator(batchsize), steps_per_epoch=889//batchsize,\n",
    "                   epochs=nepochs, verbose=2, validation_data=([xMulVal,xPanVal],yVal),callbacks=[time_callback, es]),\n",
    "                  max_queue_size=2) # I get out of memory errors, so I reduce the queue\n",
    "    # but the out of memory is probably due to the GPU rather than the CPU, so  it might not make any difference\n",
    "    xaxis.append(time_callback.times)\n",
    "    modelList.append(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to downsample 1300 image so that I can combine it with the other one\n",
    "\n",
    "This is a copy from tiramisu.py right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shared CNN parameters\n",
    "REGULARIZER_L = 1e-4\n",
    "DROPOUT_RATE = 0.2\n",
    "PADDING ='same'\n",
    "INITIALIZER = 'he_uniform'\n",
    "POOLING = (2, 2)\n",
    "\n",
    "\n",
    "def tiramisu(_input, blocks=[4, 5, 7, 10, 12], bottleneck=15,  # architecture of the tiramisu\n",
    "    n_classes=1, input_shape=(8, 325, 325)):  # properties of the data\n",
    "\n",
    "    ##########################\n",
    "    # image input # I use my own input\n",
    "    #_input = layers.Input(shape=input_shape)\n",
    "    ##########################\n",
    "    # conv layer\n",
    "    x = layers.Convolution2D(48, (3, 3), strides=(1, 1),\n",
    "                             padding=PADDING, kernel_initializer=INITIALIZER,\n",
    "                             kernel_regularizer=regularizers.l2(REGULARIZER_L))(_input)\n",
    "    ##########################\n",
    "    # down path\n",
    "    skips = []\n",
    "    for nb in blocks:\n",
    "        x = _dense_block(nb, x, end2end=True)\n",
    "        skips.append(x)\n",
    "        x = _transition_down(x)\n",
    "    ##########################\n",
    "    # bottleneck\n",
    "    x = _dense_block(bottleneck, x)\n",
    "    ##########################\n",
    "    # up path\n",
    "    for nb in blocks[::-1]:\n",
    "        tmp = skips.pop() # need to do try except for odd number, can only pop once\n",
    "        try:\n",
    "            x = layers.Concatenate(axis=1)([_transition_up(x), tmp]) # axis=1 because I use channel first\n",
    "        except ValueError:\n",
    "            x = layers.Concatenate(axis=1)([layers.ZeroPadding2D(((1, 0), (1, 0)))(_transition_up(x)), tmp])\n",
    "        x = _dense_block(nb, x)\n",
    "    ##########################\n",
    "    # conv layer\n",
    "    x = layers.Convolution2D(n_classes, (1, 1), strides=(1, 1),\n",
    "                             padding=PADDING, kernel_initializer=INITIALIZER,\n",
    "                             kernel_regularizer=regularizers.l2(REGULARIZER_L))(x)\n",
    "    ##########################\n",
    "    # segmented image output\n",
    "    x = layers.Activation('softmax')(x)\n",
    "    #_output = layers.Reshape((-1, n_classes))(x)\n",
    "    ####################################################\n",
    "    # put it together\n",
    "    #model = Model(inputs=_input, outputs=_output)\n",
    "    #return model\n",
    "    return layers.Reshape((325,325))(x) # I want to combine it with my own layers\n",
    "    # I use num_classes = 1 since for 2 classes (road or not road), we only need one output.\n",
    "    # The shape would be (1, 325, 325) so I reshape it.\n",
    "\n",
    "\n",
    "def _layer(x):\n",
    "    filters = 16  # the growth rate (# of feature maps added per layer)\n",
    "    kernel = (3, 3)\n",
    "    stride = (1, 1)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.BatchNormalization(axis=1, center=False, scale=False)(x)\n",
    "    x = layers.Convolution2D(filters, kernel, strides=stride,\n",
    "                             padding=PADDING, kernel_initializer=INITIALIZER,\n",
    "                             kernel_regularizer=regularizers.l2(REGULARIZER_L))(x)\n",
    "    x = layers.Dropout(DROPOUT_RATE)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _dense_block(n_layers, x, end2end=False):\n",
    "    # if end2end, will provide a path from input to output, as well as internal paths\n",
    "    _these_layer_outputs = []\n",
    "    _start = x\n",
    "    # n-1 layers with their outputs concatted to their inputs\n",
    "    for i in range(n_layers-1):\n",
    "        lyr = _layer(x)\n",
    "        _these_layer_outputs.append(lyr)\n",
    "        x = layers.Concatenate(axis=1)([x, lyr]) # axis=0 because I use channel first\n",
    "    # one more layer, then concatenate all of the layer outputs\n",
    "    _these_layer_outputs.append(_layer(x))\n",
    "    if end2end:\n",
    "        _these_layer_outputs.append(_start)\n",
    "    x = layers.Concatenate(axis=1)(_these_layer_outputs) # axis=0 because I use channel first\n",
    "    return x\n",
    "\n",
    "\n",
    "def _transition_down(x):\n",
    "    filters = x.get_shape().as_list()[-1]  # same number of output feature maps as input\n",
    "    kernel = (1, 1)\n",
    "    stride = (1, 1)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.BatchNormalization(axis=1, center=False, scale=False)(x)\n",
    "    x = layers.Convolution2D(filters, kernel, strides=stride,\n",
    "                             padding=PADDING, kernel_initializer=INITIALIZER,\n",
    "                             kernel_regularizer=regularizers.l2(REGULARIZER_L))(x)\n",
    "    x = layers.Dropout(DROPOUT_RATE)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=POOLING, strides=POOLING)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _transition_up(x):\n",
    "    filters = x.get_shape().as_list()[-1]  # same number of output feature maps as input\n",
    "    kernel = (3, 3)\n",
    "    x = layers.Conv2DTranspose(filters, kernel, strides=POOLING,\n",
    "                               padding=PADDING, kernel_initializer=INITIALIZER,\n",
    "                               kernel_regularizer=regularizers.l2(REGULARIZER_L))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  file 0\n",
      "     0 / 89\n",
      "     1 / 89\n",
      "     2 / 89\n",
      "     3 / 89\n",
      "     4 / 89\n",
      "     5 / 89\n",
      "     6 / 89\n",
      "     7 / 89\n",
      "     8 / 89\n",
      "     9 / 89\n",
      "     10 / 89\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,258,325,325]\n\t [[Node: gradients/conv2d_19/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, _class=[\"loc:@conv2d_19/convolution\"], data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/conv2d_19/convolution_grad/Shape, conv2d_19/kernel/read, gradients/conv2d_19/transpose_1_grad/transpose)]]\n\nCaused by op 'gradients/conv2d_19/convolution_grad/Conv2DBackpropInput', defined at:\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-ed45d7b43480>\", line 25, in <module>\n    train(batchsize=1, nepochs=10, timelimit=np.inf)\n  File \"<ipython-input-2-b9b9abfa1f87>\", line 67, in train\n    epochs=nepochs, verbose=2, validation_data=([xMulVal,xPanVal],yVal),callbacks=[time_callback, es]),\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1725, in fit_generator\n    self._make_train_function()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 937, in _make_train_function\n    self.total_loss)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizers.py\", line 404, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizers.py\", line 71, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2305, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 540, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 346, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 540, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 445, in _Conv2DGrad\n    op.get_attr(\"data_format\")),\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 488, in conv2d_backprop_input\n    data_format=data_format, name=name)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'conv2d_19/convolution', defined at:\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-4-ed45d7b43480>\", line 25, in <module>\n    train(batchsize=1, nepochs=10, timelimit=np.inf)\n  File \"<ipython-input-2-b9b9abfa1f87>\", line 58, in train\n    Y = NN(XMul,XPan)\n  File \"<ipython-input-4-ed45d7b43480>\", line 20, in NN\n    x = tiramisu(x, blocks=[2, 3], bottleneck = 4, input_shape=(8+num_channel_Pan, 325, 325))\n  File \"<ipython-input-3-9d24d8306db6>\", line 38, in tiramisu\n    x = _dense_block(nb, x)\n  File \"<ipython-input-3-9d24d8306db6>\", line 80, in _dense_block\n    _these_layer_outputs.append(_layer(x))\n  File \"<ipython-input-3-9d24d8306db6>\", line 65, in _layer\n    kernel_regularizer=regularizers.l2(REGULARIZER_L))(x)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 596, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3156, in conv2d\n    data_format='NHWC')\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 670, in convolution\n    op=op)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 338, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 662, in op\n    name=name)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 131, in _non_atrous_convolution\n    name=name)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 399, in conv2d\n    data_format=data_format, name=name)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,258,325,325]\n\t [[Node: gradients/conv2d_19/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, _class=[\"loc:@conv2d_19/convolution\"], data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/conv2d_19/convolution_grad/Shape, conv2d_19/kernel/read, gradients/conv2d_19/transpose_1_grad/transpose)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,258,325,325]\n\t [[Node: gradients/conv2d_19/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, _class=[\"loc:@conv2d_19/convolution\"], data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/conv2d_19/convolution_grad/Shape, conv2d_19/kernel/read, gradients/conv2d_19/transpose_1_grad/transpose)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ed45d7b43480>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimelimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-b9b9abfa1f87>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(batchsize, nepochs, timelimit)\u001b[0m\n\u001b[0;32m     65\u001b[0m                   loss='binary_crossentropy')\n\u001b[0;32m     66\u001b[0m     history.append(model.fit_generator(generator(batchsize), steps_per_epoch=889//batchsize,\n\u001b[1;32m---> 67\u001b[1;33m                    epochs=nepochs, verbose=2, validation_data=([xMulVal,xPanVal],yVal),callbacks=[time_callback, es]),\n\u001b[0m\u001b[0;32m     68\u001b[0m                   max_queue_size=2) # I get out of memory errors, so I reduce the queue\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m# but the out of memory is probably due to the GPU rather than the CPU, so  it might not make any difference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1840\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2268\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,258,325,325]\n\t [[Node: gradients/conv2d_19/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, _class=[\"loc:@conv2d_19/convolution\"], data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/conv2d_19/convolution_grad/Shape, conv2d_19/kernel/read, gradients/conv2d_19/transpose_1_grad/transpose)]]\n\nCaused by op 'gradients/conv2d_19/convolution_grad/Conv2DBackpropInput', defined at:\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-ed45d7b43480>\", line 25, in <module>\n    train(batchsize=1, nepochs=10, timelimit=np.inf)\n  File \"<ipython-input-2-b9b9abfa1f87>\", line 67, in train\n    epochs=nepochs, verbose=2, validation_data=([xMulVal,xPanVal],yVal),callbacks=[time_callback, es]),\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1725, in fit_generator\n    self._make_train_function()\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 937, in _make_train_function\n    self.total_loss)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizers.py\", line 404, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizers.py\", line 71, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2305, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 540, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 346, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 540, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 445, in _Conv2DGrad\n    op.get_attr(\"data_format\")),\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 488, in conv2d_backprop_input\n    data_format=data_format, name=name)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'conv2d_19/convolution', defined at:\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-4-ed45d7b43480>\", line 25, in <module>\n    train(batchsize=1, nepochs=10, timelimit=np.inf)\n  File \"<ipython-input-2-b9b9abfa1f87>\", line 58, in train\n    Y = NN(XMul,XPan)\n  File \"<ipython-input-4-ed45d7b43480>\", line 20, in NN\n    x = tiramisu(x, blocks=[2, 3], bottleneck = 4, input_shape=(8+num_channel_Pan, 325, 325))\n  File \"<ipython-input-3-9d24d8306db6>\", line 38, in tiramisu\n    x = _dense_block(nb, x)\n  File \"<ipython-input-3-9d24d8306db6>\", line 80, in _dense_block\n    _these_layer_outputs.append(_layer(x))\n  File \"<ipython-input-3-9d24d8306db6>\", line 65, in _layer\n    kernel_regularizer=regularizers.l2(REGULARIZER_L))(x)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 596, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3156, in conv2d\n    data_format='NHWC')\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 670, in convolution\n    op=op)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 338, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 662, in op\n    name=name)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 131, in _non_atrous_convolution\n    name=name)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 399, in conv2d\n    data_format=data_format, name=name)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\nicol\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,258,325,325]\n\t [[Node: gradients/conv2d_19/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, _class=[\"loc:@conv2d_19/convolution\"], data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/conv2d_19/convolution_grad/Shape, conv2d_19/kernel/read, gradients/conv2d_19/transpose_1_grad/transpose)]]\n"
     ]
    }
   ],
   "source": [
    "K.set_image_data_format(\"channels_first\")\n",
    "def NN(XMul,XPan): # XMul is of shape (100, 8, 325, 325), XPan is (100, 1, 1300, 1300), output is (100, 1300, 1300)\n",
    "    num_channel_Pan = 4\n",
    "    \n",
    "    x = layers.Conv2D(num_channel_Pan//2,(3, 3), strides=(1,1), padding=PADDING, kernel_initializer=INITIALIZER,\n",
    "                               kernel_regularizer=regularizers.l2(REGULARIZER_L))(XPan) # need to do 2x2 pooling twice\n",
    "    x = layers.Dropout(DROPOUT_RATE)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=POOLING, strides=POOLING)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.BatchNormalization(axis=1, center=False, scale=False)(x)\n",
    "    x = layers.Conv2D(num_channel_Pan,(3, 3), strides=(1,1), padding=PADDING, kernel_initializer=INITIALIZER,\n",
    "                               kernel_regularizer=regularizers.l2(REGULARIZER_L))(x)\n",
    "    x = layers.Dropout(DROPOUT_RATE)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=POOLING, strides=POOLING)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.BatchNormalization(axis=1, center=False, scale=False)(x)\n",
    "    \n",
    "    x = layers.Concatenate(axis=1)([x,XMul]) # channel axis\n",
    "    # I think it needs to be dividible 32 times, so it needs 320 or 352. I put a try except to do the padding just when needed\n",
    "    x = tiramisu(x, blocks=[2, 3], bottleneck = 4, input_shape=(8+num_channel_Pan, 325, 325))\n",
    "    # blocks was [4, 5, 7, 10, 12], but I have a ResourceExhaustedError and also I don't think we need the full tiramisu for\n",
    "    # this simple task. bottleneck was 15\n",
    "    return x\n",
    "\n",
    "train(batchsize=1, nepochs=10, timelimit=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got ResourceExhaustedError  during 64 / 89 of file 1 for batchsize of 16. Memory is 94% (5.6 GB for python, 1 GB for google). I don't know why this file needs so much memory\n",
    "\n",
    "I got ResourceExhaustedError  during 40 / 89 of file 0 for batchsize of 4. Memory is 94% (5.6 GB for python, 1 GB for google). I don't know why this file needs so much memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model summary\n",
    "\n",
    "bug: layers.BatchNormalization(axis=1, center=False, scale=False)(x) should use 0 parameters because of False\n",
    "\n",
    "I should use image patch to reduce the memory need.\n",
    "\n",
    "Or I can use a neuro network that is smaller than the Tiramisu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 1, 1300, 1300) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 2, 1300, 1300) 20          input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 2, 1300, 1300) 0           conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 2, 650, 650)   0           dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 2, 650, 650)   0           max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 2, 650, 650)   4           activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 4, 650, 650)   76          batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 4, 650, 650)   0           conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, 4, 325, 325)   0           dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 4, 325, 325)   0           max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 4, 325, 325)   8           activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 8, 325, 325)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)     (None, 12, 325, 325)  0           batch_normalization_20[0][0]     \n",
      "                                                                   input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 48, 325, 325)  5232        concatenate_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 48, 325, 325)  0           conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 48, 325, 325)  96          activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 16, 325, 325)  6928        batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, 16, 325, 325)  0           conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)     (None, 64, 325, 325)  0           conv2d_23[0][0]                  \n",
      "                                                                   dropout_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 64, 325, 325)  0           concatenate_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 64, 325, 325)  128         activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 16, 325, 325)  9232        batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 16, 325, 325)  0           conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)     (None, 80, 325, 325)  0           dropout_21[0][0]                 \n",
      "                                                                   dropout_22[0][0]                 \n",
      "                                                                   conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 80, 325, 325)  0           concatenate_21[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 80, 325, 325)  160         activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 325, 325, 325) 26325       batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 325, 325, 325) 0           conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, 325, 162, 162) 0           dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 325, 162, 162) 0           max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 325, 162, 162) 650         activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 16, 162, 162)  46816       batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 16, 162, 162)  0           conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)     (None, 341, 162, 162) 0           max_pooling2d_7[0][0]            \n",
      "                                                                   dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 341, 162, 162) 0           concatenate_22[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 341, 162, 162) 682         activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 16, 162, 162)  49120       batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, 16, 162, 162)  0           conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)     (None, 357, 162, 162) 0           concatenate_22[0][0]             \n",
      "                                                                   dropout_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 357, 162, 162) 0           concatenate_23[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 357, 162, 162) 714         activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 16, 162, 162)  51424       batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)             (None, 16, 162, 162)  0           conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)     (None, 373, 162, 162) 0           dropout_24[0][0]                 \n",
      "                                                                   dropout_25[0][0]                 \n",
      "                                                                   dropout_26[0][0]                 \n",
      "                                                                   max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 373, 162, 162) 0           concatenate_24[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 373, 162, 162) 746         activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 162, 162, 162) 60588       batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)             (None, 162, 162, 162) 0           conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)   (None, 162, 81, 81)   0           dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 162, 81, 81)   0           max_pooling2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 162, 81, 81)   324         activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 16, 81, 81)    23344       batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)             (None, 16, 81, 81)    0           conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)     (None, 178, 81, 81)   0           max_pooling2d_8[0][0]            \n",
      "                                                                   dropout_28[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 178, 81, 81)   0           concatenate_25[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 178, 81, 81)   356         activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 16, 81, 81)    25648       batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)             (None, 16, 81, 81)    0           conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)     (None, 194, 81, 81)   0           concatenate_25[0][0]             \n",
      "                                                                   dropout_29[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 194, 81, 81)   0           concatenate_26[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 194, 81, 81)   388         activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 16, 81, 81)    27952       batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)             (None, 16, 81, 81)    0           conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)     (None, 210, 81, 81)   0           concatenate_26[0][0]             \n",
      "                                                                   dropout_30[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 210, 81, 81)   0           concatenate_27[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 210, 81, 81)   420         activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 16, 81, 81)    30256       batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)             (None, 16, 81, 81)    0           conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)     (None, 64, 81, 81)    0           dropout_28[0][0]                 \n",
      "                                                                   dropout_29[0][0]                 \n",
      "                                                                   dropout_30[0][0]                 \n",
      "                                                                   dropout_31[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTransp (None, 81, 162, 162)  46737       concatenate_28[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)     (None, 454, 162, 162) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                   concatenate_24[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 454, 162, 162) 0           concatenate_29[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 454, 162, 162) 908         activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 16, 162, 162)  65392       batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 16, 162, 162)  0           conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)     (None, 470, 162, 162) 0           concatenate_29[0][0]             \n",
      "                                                                   dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 470, 162, 162) 0           concatenate_30[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 470, 162, 162) 940         activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 16, 162, 162)  67696       batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 16, 162, 162)  0           conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)     (None, 486, 162, 162) 0           concatenate_30[0][0]             \n",
      "                                                                   dropout_33[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 486, 162, 162) 0           concatenate_31[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 486, 162, 162) 972         activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 16, 162, 162)  70000       batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 16, 162, 162)  0           conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)     (None, 48, 162, 162)  0           dropout_32[0][0]                 \n",
      "                                                                   dropout_33[0][0]                 \n",
      "                                                                   dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTransp (None, 162, 324, 324) 70146       concatenate_32[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D) (None, 162, 325, 325) 0           conv2d_transpose_6[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)     (None, 242, 325, 325) 0           zero_padding2d_2[0][0]           \n",
      "                                                                   concatenate_21[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 242, 325, 325) 0           concatenate_34[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 242, 325, 325) 484         activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 16, 325, 325)  34864       batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)             (None, 16, 325, 325)  0           conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)     (None, 258, 325, 325) 0           concatenate_34[0][0]             \n",
      "                                                                   dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 258, 325, 325) 0           concatenate_35[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 258, 325, 325) 516         activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, 16, 325, 325)  37168       batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)             (None, 16, 325, 325)  0           conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)     (None, 32, 325, 325)  0           dropout_35[0][0]                 \n",
      "                                                                   dropout_36[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 1, 325, 325)   33          concatenate_36[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 1, 325, 325)   0           conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 325, 325)      0           activation_38[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 763,493\n",
      "Trainable params: 754,997\n",
      "Non-trainable params: 8,496\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "XMul = layers.Input(shape=xMulVal.shape[1:])\n",
    "XPan = layers.Input(shape=xPanVal.shape[1:])\n",
    "\n",
    "# Actual neural netowrk given by function NN\n",
    "Y = NN(XMul,XPan)\n",
    "\n",
    "model = Model(inputs=[XMul,XPan], outputs=Y)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflowgpu]",
   "language": "python",
   "name": "conda-env-tensorflowgpu-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
