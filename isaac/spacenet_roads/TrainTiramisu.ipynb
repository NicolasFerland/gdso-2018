{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceNet Roads Challenge\n",
    "\n",
    "This notebook walks through the training of a [tiramisu](https://arxiv.org/pdf/1611.09326.pdf) segmentation network to be a road detector on the SpaceNet AOI 2 (Las Vegas) data set.\n",
    "\n",
    "I use a relatively small version of the tiramiusu (not the full 103-layer version preferred by that paper), with a batch size of 1 on relatively small (256x256) subimages, so as to fit this effort into the limited RAM of the GPU in my home desktop.\n",
    "\n",
    "All the same, I think I acheive reasonable results, with the network training up to an accuracy of 92% or 93% on the validation set after 9 hours (and beginning to over-fit the training data after that - training data accuracy shown in the first plot and validation data accuracy shown in the second):\n",
    "\n",
    "![Training accuracy](plots/training_accuracy_curve.png)\n",
    "![Validation accuracy](plots/validation_accuracy_curve.png)\n",
    "\n",
    "(Those plots are both captured from [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard), aimed at the logfile produced by the `TensorBoard` callback used in training.)\n",
    "\n",
    "I'll move forward with the network weights as they were around the peak of that validation accuracy curve and before it began to over-fit: **epoch 85**.\n",
    "\n",
    "Here's what that network's performance looks like on a few random tiles from the validation data:\n",
    "\n",
    "![performance](plots/val/run-01/epoch-085.png)\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "**Note:** this training session cuts a few corners in important ways:\n",
    "- I train the network to identify a 20-pixel wide stripe running through the middle of each road, not the full road width (since the input labels given are the centerlines, and not a full per-pixel segmentation).  This is rough at best, and very noisy: many roads are wider than this, and dilating the centerlines the way I have muddies up many intersections.\n",
    "- I randomly sample tiles from within random images throughout training and validation: I do not ensure that every bit of training data has been seen by the network once for each epoch. Given enough training time, this works out just fine, but it makes the description of an \"epoch\" a little bit messy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from keras.optimizers import RMSprop\n",
    "from os import path, makedirs\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import run\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import SpacenetGenerator\n",
    "import tiramisu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = (256, 256)\n",
    "\n",
    "traingen = SpacenetGenerator('../../data/train/', tile_size=tile_size)\n",
    "valgen = SpacenetGenerator('../../data/val/', tile_size=tile_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a visualization callback\n",
    "\n",
    "(this can be used to generate plots showing network performance on the validation data during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotCallback(Callback):\n",
    "    \n",
    "    def __init__(self, datagen, period, savedir, *args, **kwargs):\n",
    "        self.datagen = datagen\n",
    "        self.period = period\n",
    "        self.savedir = savedir\n",
    "        # a custom colormap that is transparent at low values\n",
    "        cmap = plt.cm.copper\n",
    "        my_cmap = cmap(np.arange(cmap.N))\n",
    "        my_cmap[:, -1] = np.zeros_like(my_cmap[:, -1])\n",
    "        my_cmap[-1:, -1] = 0.75\n",
    "        my_cmap = ListedColormap(my_cmap)\n",
    "        self.my_cmap = my_cmap\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def _reshape_output(output_array, img_shape):\n",
    "        _reshaped = np.argmax(output_array[0], axis=-1)\n",
    "        _reshaped = _reshaped.reshape(img_shape[0], img_shape[1])\n",
    "        return _reshaped\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \"\"\"\n",
    "        Plots an array of five tiles and the network output for them at this epoch\n",
    "        \"\"\"\n",
    "        if not epoch % self.period:\n",
    "            fig, axs = plt.subplots(5, 2, sharex=True, sharey=True, figsize=(8, 20))\n",
    "            plt.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "            for i in range(5):\n",
    "                img, lab = next(self.datagen)\n",
    "                pred = self.model.predict(img, batch_size=1)\n",
    "\n",
    "                lab_reshaped = self._reshape_output(lab, img[0].shape)\n",
    "                pred_reshaped = self._reshape_output(pred, img[0].shape)\n",
    "\n",
    "                axs[i, 0].imshow(img[0], aspect='equal')\n",
    "                axs[i, 0].imshow(lab_reshaped, vmin=0, vmax=1, cmap=self.my_cmap, aspect='equal')\n",
    "                axs[i, 1].imshow(img[0], aspect='equal')\n",
    "                axs[i, 1].imshow(pred_reshaped, vmin=0, vmax=1, cmap=self.my_cmap,aspect='equal')\n",
    "                if i == 0:\n",
    "                    axs[i, 0].set_title('ground truth')\n",
    "                    axs[i, 1].set_title('predictions'.format(epoch))\n",
    "\n",
    "            file_name = path.join(self.savedir, 'epoch-{:03d}.png'.format(epoch))\n",
    "            plt.savefig(file_name)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## put together the callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_run = 'run-01'\n",
    "\n",
    "logdir = 'logs/'\n",
    "snapdir = 'snapshots/'\n",
    "valplotdir = 'plots/val'\n",
    "trainplotdir = 'plots/train'\n",
    "for directory in [logdir, snapdir, valplotdir, trainplotdir]:\n",
    "    rundir = path.join(directory, this_run)\n",
    "    run('mkdir -p {}'.format(rundir), shell=True)\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau('loss', factor=0.2, verbose=1, patience=10, cooldown=5),\n",
    "    TensorBoard(log_dir=path.join(logdir, this_run)),\n",
    "    ModelCheckpoint(path.join(snapdir, this_run, 'modelweights.{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                    save_weights_only=False, verbose=1, period=5),\n",
    "    PlotCallback(valgen.random_generator(1), 5, path.join(valplotdir, this_run)),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiramisu.POOLING = (4, 4)\n",
    "model = tiramisu.tiramisu(n_classes=2, input_shape=(tile_size[0], tile_size[1], 3),\n",
    "                          blocks=[2, 3, 5, 7], bottleneck=9)\n",
    "\n",
    "model.compile(loss='kld', optimizer=RMSprop(2e-4), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "model.fit_generator(traingen.random_generator(batch_size),\n",
    "                    steps_per_epoch=len(traingen.images) // batch_size,\n",
    "                    epochs=500, verbose=1, callbacks=callbacks,\n",
    "                    validation_data=valgen.random_generator(batch_size),\n",
    "                    validation_steps=len(valgen.images) // batch_size,\n",
    "                    use_multiprocessing=True, workers=4,\n",
    "                   )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
